
Esta guÃ­a explica **cada parte** del resultado entregado por `glm()` cuando ajustas un modelo logÃ­stico con `family = binomial`.

```log
Call:
glm(formula = diagnosis ~ ., family = binomial, data = df)

Coefficients:
                        Estimate Std. Error z value Pr(>|z|)    
(Intercept)             -7.35952   12.85259  -0.573   0.5669    
radius_mean             -2.04930    3.71588  -0.551   0.5813    
texture_mean             0.38473    0.06454   5.961  2.5e-09 ***
perimeter_mean          -0.07151    0.50516  -0.142   0.8874    
area_mean                0.03980    0.01674   2.377   0.0174 *  
smoothness_mean         76.43227   31.95492   2.392   0.0168 *  
compactness_mean        -1.46242   20.34249  -0.072   0.9427    
concavity_mean           8.46870    8.12003   1.043   0.2970    
concave.points_mean     66.82176   28.52910   2.342   0.0192 *  
symmetry_mean           16.27824   10.63059   1.531   0.1257    
fractal_dimension_mean -68.33703   85.55666  -0.799   0.4244    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 751.44  on 568  degrees of freedom
Residual deviance: 146.13  on 558  degrees of freedom
AIC: 168.13

Number of Fisher Scoring iterations: 9
```


## 1. Llamada al modelo (Call)

```r
Call:
glm(formula = diagnosis ~ ., family = binomial, data = df)
```

### Â¿QuÃ© significa?

* **`diagnosis ~ .`** â†’ la variable dependiente es `diagnosis`, y se usan **todas las demÃ¡s variables** del dataset como predictores.
* **`family = binomial`** â†’ es una **regresiÃ³n logÃ­stica** (logit).
* **`data = df`** â†’ el dataset utilizado se llama `df`.


## 2. Tabla de coeficientes

```r
Coefficients | Estimate | Std. Error | z value | Pr(>|z|)
```

Cada fila es un predictor.
Cada columna significa:
| Columna           | InterpretaciÃ³n                                      |
|-------------------|-----------------------------------------------------|
| **Estimate**      | Coeficiente estimado Î² (efecto sobre el logit).     |
| **Std. Error**    | Error estÃ¡ndar del coeficiente.                     |
| **z value**       | EstadÃ­stico z = Î² / SE.                             |
| **Pr(>\|z\|)**      | p-value del test Hâ‚€: Î² = 0.                          |
| **Signif. codes** | Asteriscos indicando nivel de significancia.        |


### **Estimate ($\beta$)**  
Es el efecto del predictor sobre el **logit**:

$$
\log\left(\frac{p}{1-p}\right) = X\beta
$$

- $\beta > 0$ â†’ aumenta la probabilidad del evento (diagnosis = maligno).  
- $\beta < 0$ â†’ la disminuye.

Para interpretar en tÃ©rminos de *odds*, usamos:

$$
OR = e^{\beta}
$$

Ejemplo:  
`texture_mean = 0.38473`

$$
OR = e^{0.38473} = 1.47
$$

â†’ aumenta los *odds* en 47%.



### **Std. Error**

Mide la **incertidumbre** del coeficiente.

- SE pequeÃ±o â†’ $\beta$ es confiable.  
- SE grande â†’ hay ruido o inestabilidad numÃ©rica.

En este modelo, algunas variables tienen SE enormes (p. ej. fractal\_dimension\_mean), lo que indica:

- falta de escalamiento  
- multicolinealidad  
- predictores redundantes  



### **z value**

Es:

$$
z = \frac{\beta}{SE}
$$

Indica cuÃ¡ntas desviaciones estÃ¡ndar estÃ¡ el coeficiente lejos de 0.

- $|z|$ grande â†’ fuerte evidencia contra $H_0$.  
- $|z|$ pequeÃ±o â†’ la variable podrÃ­a no importar.

Ejemplo:

`texture_mean`:

$$
z = \frac{0.38473}{0.06454} = 5.961
$$

â†’ muy significativo.



### **Pr(>|z|) = p-value**

Es la probabilidad de obtener un valor $z$ tan extremo **asumiendo que $H_0$ es verdadera**.

$$
H_0: \beta = 0
$$

InterpretaciÃ³n:

- p < 0.05 â†’ el predictor aporta al modelo.  
- p â‰¥ 0.05 â†’ no hay evidencia de efecto.

**Nota importante:**  
el p-value NO dice â€œla probabilidad de que Hâ‚€ sea verdaderaâ€.  
Dice cuÃ¡n extremo serÃ­a el estimate **si realmente $\beta = 0$**.



### **Signif. codes**

Son atajos visuales:

- `***` p < 0.001 â†’ muy fuerte evidencia  
- `**` p < 0.01  
- `*` p < 0.05  
- `.` p < 0.1  
- vacÃ­o â†’ no significativo


## 3. Variables significativas vs. no significativas

### Significativas (aportan al modelo)

* `texture_mean`
* `area_mean`
* `smoothness_mean`
* `concave.points_mean`

### No significativas (no aportan de forma independiente)

* `radius_mean`
* `perimeter_mean`
* `compactness_mean`
* `concavity_mean`
* `symmetry_mean`
* `fractal_dimension_mean`

Esto puede ocurrir por:

- Multicolinealidad (predictoras muy correlacionadas entre sÃ­).  
- Redundancia en variables.  
- Efectos pequeÃ±os comparados con el ruido.  
- Falta de escala homogÃ©nea.  
- Estos predictores probablemente serÃ­an eliminados por **Lasso**.

### Problemas de escala numÃ©rica detectados

Coeficientes gigantes como 76.43 o -68.33 indican que el modelo usado con datos **sin estandarizar** es numÃ©ricamente inestable.

Esto afecta:

- estimates  
- std.errors  
- interpretabilidad  
- p-values  
- odds ratios

La recomendaciÃ³n profesional es **estandarizar todas las variables antes de usar una regresiÃ³n logÃ­stica multivariada**.



## 4. ParÃ¡metro de dispersiÃ³n

```r
(Dispersion parameter for binomial family taken to be 1)
```

En regresiÃ³n logÃ­stica SIEMPRE es 1.
Nada que interpretar.


## 5. Deviance

```r
Null deviance: 751.44  on 568  degrees of freedom
Residual deviance: 146.13  on 558  degrees of freedom
```

### **Null deviance**

Error del modelo que NO usa predictores (solo la media).
Sirve como referencia.

### **Residual deviance**

Error del modelo con los predictores incluidos.

### Degrees of fredom

Los grados de libertad indican cuÃ¡ntos datos "libres" quedan para medir el error, despuÃ©s de descontar los parÃ¡metros que el modelo estima.

### InterpretaciÃ³n crucial

* Si la deviance disminuye muchÃ­simo â†’ el modelo **explica bien** la variable objetivo.
* AquÃ­ la reducciÃ³n es grande:

**751 â†’ 146**

Esto indica un modelo **muy bueno**.


## 6. AIC

```r
AIC: 168.13
```

El **Akaike Information Criterion**:

* Penaliza por complejidad.
* **MÃ¡s pequeÃ±o = mejor**, pero solo al comparar modelos.


## 7. Iteraciones del algoritmo

```r
Number of Fisher Scoring iterations: 9
```
* NÃºmero de pasos que necesitÃ³ el algoritmo para converger.
* Valores entre 4 y 15 son normales.


# ğŸ” Resumen simplificado

* El modelo estÃ¡ bien ajustado y convergiÃ³ sin problemas.
* La deviance baja muchÃ­simo â†’ **alto poder explicativo**.
* Solo algunas variables son realmente importantes estadÃ­sticamente.
* AIC=168 es bueno, pero Ãºtil solo comparado con otros modelos.
* Los coeficientes indican direcciÃ³n e impacto sobre la probabilidad.
