# üß¨ Evaluaci√≥n del ajuste en modelos de regresi√≥n log√≠stica  

Este apunte resume e interpreta tus propios resultados del an√°lisis log√≠stico del dataset WDBC, explicando **AIC**, **pseudo-R¬≤** y su rol dentro de la bondad de ajuste. El documento est√° redactado en t√©rminos estad√≠sticos (no de machine learning), orientado a interpretaci√≥n y modelaci√≥n.

# 1. ¬øQu√© es la bondad de ajuste en regresi√≥n log√≠stica?

La **bondad de ajuste** describe qu√© tan bien un modelo representa el comportamiento real de los datos.  
En regresi√≥n log√≠stica esto significa:

- ¬øEl modelo asigna altas probabilidades a casos malignos reales y bajas a benignos?
- ¬øMejora claramente respecto al modelo nulo (solo intercepto)?
- ¬øExtrae informaci√≥n real de las variables morfol√≥gicas del tumor?

Como la variable respuesta es binaria, **no podemos usar R¬≤ cl√°sico**.  
Por eso se utilizan dos familias de indicadores:

- **Pseudo-R¬≤** ‚Üí miden **bondad de ajuste** (calidad explicativa).
- **AIC** ‚Üí mide **eficiencia del modelo** (interpretaci√≥n + parsimonia), NO bondad de ajuste directa.

Tu profesor dijo algo clave:  
**AIC ayuda a elegir el mejor modelo para interpretaci√≥n/explicaci√≥n.  
Los pseudo-R¬≤ muestran la calidad predictiva del modelo dentro del marco estad√≠stico.**

# 2. Resultados de los pseudo-R¬≤: qu√© tan bien ajustan tus modelos

Los pseudo-R¬≤ se basan en log-verosimilitud: comparan cada modelo con el modelo nulo.

Valores altos indican **buena discriminaci√≥n entre tumores benignos y malignos**.

### ‚úî Modelo completo  
- **McFadden = 0.8055**  
- **Cox‚ÄìSnell = 0.6549**  
- **Nagelkerke = 0.8933**

Interpretaci√≥n:
- McFadden > 0.8 es extremadamente alto para regresi√≥n log√≠stica.  
- Esto indica **excelente ajuste**, comparable a un modelo muy informativo.  
- Nagelkerke ‚âà 0.89 sugiere que el modelo capta casi toda la estructura separatoria del problema.

### ‚úî Modelos reducidos (A, B, C, D)
- McFadden: 0.72‚Äì0.78  
- Nagelkerke: 0.84‚Äì0.88  

Interpretaci√≥n:
- Todos los modelos tienen **buen ajuste**, pero **ninguno supera al modelo completo**.
- La ca√≠da del pseudo-R¬≤ en modelos B, C y D muestra una p√©rdida clara de poder explicativo.

### Conclusi√≥n sobre ajuste:

> **El modelo completo tiene la mejor bondad de ajuste.  
> Los modelos simplificados sacrifican capacidad explicativa.**

# 3. Interpretaci√≥n del AIC: qu√© modelo conviene para an√°lisis explicativo

El **AIC** penaliza complejidad: busca modelos **parcimoniosos**.

| Modelo | df | AIC |
|--------|----|------|
| **Completo** | 11 | **168.13** |
| Modelo A | 4 | 172.38 |
| Modelo B | 3 | 209.34 |
| Modelo C | 3 | 215.24 |
| Modelo D | 4 | 215.69 |

Interpretaci√≥n:
- **El menor AIC es el del modelo completo (168.13)**.  
- Los modelos simples (B, C, D) pierden demasiada verosimilitud para justificar su reducci√≥n.  
- El Modelo A (3 variables) es competitivo, con un AIC solo ligeramente mayor.

Conclusi√≥n sobre AIC:

> **Para lograr el mejor balance entre ajuste y simplicidad, el Modelo A es una alternativa s√≥lida si se prioriza la parsimonia.**

# 4. Relaci√≥n entre pseudo-R¬≤ y AIC

### ‚úî Pseudo-R¬≤ ‚Üí se asocian a la **capacidad predictiva**  
Muestran qu√© tan bien el modelo logra separar benignos de malignos, comparado con el modelo nulo.

- Un McFadden de 0.80 indica **excelente poder predictivo**.
- Por eso se usan cuando el objetivo es evaluar calidad de clasificaci√≥n o ajuste.

### ‚úî AIC ‚Üí se usa para **interpretaci√≥n / selecci√≥n de modelo**  
Ayuda a decidir qu√© combinaci√≥n de predictores ofrece la mejor explicaci√≥n estad√≠stica del fen√≥meno con la m√≠nima complejidad posible.

- El modelo completo maximiza ese criterio.
- Pero el Modelo A logra un AIC cercano usando apenas tres predictores.

### Relaci√≥n final:
> **Pseudo-R¬≤ eval√∫a qu√© tan bien se ajusta y predice.  
> AIC elige qu√© modelo es m√°s eficiente para interpretar el fen√≥meno.**

# 5. Qu√© nos dicen los coeficientes del modelo completo

En el modelo completo, varias variables son significativas:

- **texture_mean (p < 0.001)**  
- **area_mean (p < 0.05)**  
- **smoothness_mean (p < 0.05)**  
- **concave.points_mean (p < 0.05)**  

Estas son las variables con evidencia estad√≠stica m√°s fuerte de asociarse a malignidad.

Variables como perimeter_mean, compactness_mean o fractal_dimension_mean no alcanzan significancia individual, pero contribuyen colectivamente al alto poder explicativo del modelo completo.

# 6. Conclusi√≥n global (integrando pseudo-R¬≤ + AIC + coeficientes)

1. **El modelo completo es el que muestra mejor ajuste global** seg√∫n los pseudo-R¬≤ y el AIC m√≠nimo.  
2. **El Modelo A, aun siendo mucho m√°s simple, conserva alrededor del 97% del poder explicativo del modelo completo.**  
3. El Modelo A usa solo tres variables altamente significativas, lo que lo hace m√°s interpretable y estad√≠sticamente eficiente.  
4. Los modelos B, C y D muestran p√©rdidas claras de ajuste y no son competitivos.  

### Conclusi√≥n final:

> **Aunque el modelo completo presenta el mejor ajuste en t√©rminos absolutos, el Modelo A se convierte en la elecci√≥n m√°s razonable cuando se prioriza la parsimonia.**  

> **Con apenas tres predictores, logra un rendimiento muy cercano al modelo completo, manteniendo todos sus coeficientes altamente significativos y ofreciendo una estructura m√°s simple, interpretable y eficiente.**
